# The file contains default configuration that can be used to run the job locally

# AWS Credentials. Needed for authenticating to ECR via the aws-cli: https://aws.amazon.com/cli/
datajobs.aws.accessKeyId=
datajobs.aws.secretAccessKey=

datajobs.kadmin_user=
datajobs.kadmin_password=
datajobs.kerberos.principal.suffix=-taurus
# Credentials in case the registry type is harbor with robot account for Harbor registry:
datajobs.docker.registryUsername=
datajobs.docker.registryPassword=

# Path to an ini config file that contains vdk runtime options
# src/main/resources/vdk_options.ini can be used for testing
datajobs.vdk_options_ini=

datajobs.deployment.k8s.kubeconfig=${HOME}/.kube/config
datajobs.deployment.k8s.namespace=default
datajobs.deployment.supportedPythonVersions={3.9: {vdkImage: 'registry.hub.docker.com/versatiledatakit/quickstart-vdk:release', baseImage: 'python:3.9-slim'}}
datajobs.deployment.defaultPythonVersion=3.9

# The owner name and email address that will be used to send all Versatile Data Kit related email notifications.
datajobs.notification.owner.email=versatiledatakit@groups.vmware.com
datajobs.notification.owner.name=Versatile Data Kit

# The gitlab repository and credentials for pulling data jobs code when building their images.
datajobs.git.url=
datajobs.git.username=
datajobs.git.password=

# Docker repository used to store Versatile Data Kit images (ECR)
datajobs.docker.repositoryUrl=ghcr.io/versatile-data-kit-dev/dp
# Image name of VDK which will be used to run the data jobs
datajobs.vdk.image=registry.hub.docker.com/versatiledatakit/quickstart-vdk:release

# AWS ECR region. Needed for authenticating to ECR via the aws-cli: https://aws.amazon.com/cli/
datajobs.aws.region=us-west-2

featureflag.security.enabled=false
spring.security.oauth2.resourceserver.jwt.jwk-set-uri=https://console-stg.cloud.vmware.com/csp/gateway/am/api/auth/token-public-key?format=jwks
spring.security.oauth2.resourceserver.jwt.issuer-uri=https://gaz-preview.csp-vidm-prod.com

# The CSP Auth Token doesn't contain the user permissions in the default location - the authorities
# field of the JWT token. This property specifies a custom location for the authorities field.
datajobs.authorization.authorities-claim-name=perms

# Name of a claim in the JWT token that needs to be validated.
# An example use case would be to validate if a CSP Organization Id is allowed to access and modify resources.
datajobs.authorization.custom-claim-name=context_name

# A comma separated list of allowed values for the JWT claim specified in "datajobs.authorization.custom-claim-name".
# If the list is empty, the claim is not validated. E.g. list of authorized CSP Organization Ids.
datajobs.authorization.authorized-custom-claim-values=d1c9dceb-ed7e-48eb-b21f-25798945e911

# A comma separated list of roles. Users whose tokens contain at least one of the roles
# are allowed to access and modify TPCS resources. If the list is empty, roles are not validated.
# E.g. "external/f399c40d-fb5e-4d24-8041-20b82471c6be/taurus:service-owner,external/65ecda65-2975-4a9c-b982-ccf52755296d/tpcs:admin"
datajobs.authorization.authorized-roles=external/f399c40d-fb5e-4d24-8041-20b82471c6be/taurus:service-user

featureflag.authorization.enabled=true
datajobs.authorization.webhook.endpoint=https://httpbin.org/post

# Image name of the data jobs builder
datajobs.builder.image=versatiledatakit/job-builder:latest

# Public proxy which is used when pulling data jobs images
datajobs.proxy.repositoryUrl=ghcr.io/versatile-data-kit-dev/dp

# Credentials with read and write access to the repository containing the data jobs
# Different public Git repositories require different approaches for access token as per:
# https://www.codeaffine.com/2014/12/09/jgit-authentication/
# Use your own credentials for development purposes
datajobs.git.read.write.username=
datajobs.git.read.write.password=

datajobs.control.k8s.namespace=default
# Location to a K8s cronjob yaml file which will be used as a template
# for all data jobs. If the location is missing, the default internal
# cronjob yaml resource will be used (see k8s-data-job-template.yaml).
# Note that this location is expected to be set via the environment
# variable 'K8S_DATA_JOB_TEMPLATE_FILE'.
#datajobs.control.k8s.data.job.template.file=${K8S_DATA_JOB_TEMPLATE_FILE:#{null}}

# Webhook URL to send telemetry events via HTTP POST requests with a JSON payload
# like http requests ; important api calls, etc
# datajobs.telemetry.webhook.endpoint
