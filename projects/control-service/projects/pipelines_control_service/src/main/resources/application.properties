# The file contains default configuration used in both production and development setup.

# Used for log file name
taurus.svc.name=data-jobs
# http://localhost:8080/${svc.url.prefix}/debug/servertime
sccp.svc.url.prefix=data-jobs
# http://localhost:8080/${svc.url.prefix}/debug
management.endpoints.web.base-path=/data-jobs/debug
management.endpoints.web.exposure.include=*

datajobs.version=0.0.1

spring.profiles.active=dev

# When updating or adding ports for services, these changes must be made in many places:
# 1) In each of the values.yml files at /k8s/envs/*/values.yml
# 2) In each service's application.properties at /services/*/src/main/resources/application.*
# 3) In base's service discovery enum at /libraries/base/src/main/java/com/vmware/taurus/discovery/ServiceLocation.java
server.port=8092

# We use Flyway (https://flywaydb.org/) for explicit database schema definition and migrations, so we disable Hibernate
# automated schema management. The automated management would be too opaque.
# The explicit migrations are defined in /src/main/resources/db.migration.
spring.jpa.hibernate.ddl-auto=none

# show-sql doesn't use logging but just prints to stdout
# to see SQL statements via logging enable DEBUG level on logger org.hibernate.SQL
# to see parameter values of SQL statements enable TRACE level on logger org.hibernate.type.descriptor.sql.BasicBinder
# NB: you can use a spring or JVM property in the form - logging.level.LOGGER_NAME=LEVEL - to override a level
# or environment variable LOGGING_LEVEL_LOGGER_NAME=LEVEL
# See https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-custom-log-levels
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.show_sql=false
logging.level.org.hibernate.SQL=INFO
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=INFO

spring.jpa.open-in-view=false

# Authorization configuration. Note if you enable authorization you should
# also point the webhook endpoint against which authorization is delegated
# in order for the feature to fully work
featureflag.authorization.enabled=false
datajobs.authorization.webhook.endpoint=
datajobs.authorization.jwt.claim.username=username

# Data Jobs post webhook settings (Create and Delete)
datajobs.post.create.webhook.endpoint=
datajobs.post.create.webhook.internal.errors.retries=3
datajobs.post.delete.webhook.endpoint=
datajobs.post.delete.webhook.internal.errors.retries=3

# The owner name and email address that will be used to send all Versatile Data Kit related email notifications.
datajobs.notification.owner.email=versatiledatakit@groups.vmware.com
datajobs.notification.owner.name=Versatile Data Kit

# The gitlab repository and credentials for pulling data jobs code when building their images.
datajobs.git.url=${GIT_URL}
datajobs.git.username=${GIT_USERNAME}
datajobs.git.password=${GIT_PASSWORD}
datajobs.git.branch=${GIT_BRANCH:master}
datajobs.git.remote=${GIT_REMOTE:origin}
# The registry type, if left blank, defaults to ecr. The alternative registry type is generic
# which means the registry is of the Harbor or Dockerhub type.
datajobs.docker.registryType=generic

# Docker repository used to store Versatile Data Kit images
datajobs.docker.repositoryUrl=hub.docker.com/versatiledatakitjobs

# open API generator is not generating example for parameters and causing noisy warnings
logging.level.io.swagger.models.parameters.AbstractSerializableParameter=ERROR

datajobs.control.k8s.namespace=
datajobs.control.k8s.kubeconfig=${HOME}/.kube/config
# Location to a K8s cronjob yaml file which will be used as a template
# for all data jobs. If the location is missing, the default internal
# cronjob yaml resource will be used (see k8s-data-job-template.yaml).
# Note that this location is expected to be set via the environment
# variable '# variable 'K8S_DATA_JOB_TEMPLATE_FILE'.'.
datajobs.control.k8s.data.job.template.file=${K8S_DATA_JOB_TEMPLATE_FILE:#{null}}

datajobs.monitoring.sync.interval=5000
datajobs.monitoring.sync.initial.delay=10000

# The status watch interval is the time period (expressed in milliseconds) after a status
# watch operation has completed and before a new one is started
datajobs.status.watch.interval=1000
# The status watch initial delay is the period (expressed in milliseconds) between control service
# start and the first time a data job status watch is started by the control service instance
datajobs.status.watch.initial.delay=10000

# The base image which will be used to create the image where data job would be run
# On top of it the job source and its dependencies are installed for each job
datajobs.deployment.dataJobBaseImage=python:3.9-slim
